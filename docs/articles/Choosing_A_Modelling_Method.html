<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Choosing A Modelling Method • zoontutorials</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">zoontutorials</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Choosing_A_Modelling_Method.html">Choosing A Modelling Method</a>
    </li>
    <li>
      <a href="../articles/Data_Exploration.html">Data exploration</a>
    </li>
    <li>
      <a href="../articles/Data_Sources.html">Data Sources</a>
    </li>
    <li>
      <a href="../articles/Introduction.html">Introduction to SDMs</a>
    </li>
    <li>
      <a href="../articles/Model_Validation.html">Model Evaluation</a>
    </li>
    <li>
      <a href="../articles/Reproducibility.html">Reproducibility</a>
    </li>
    <li>
      <a href="../articles/Selecting_Covariates.html">Selecting and preparing covariates</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Choosing A Modelling Method</h1>
            
          </div>

    
    
<div class="contents">
<hr>
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>In order to fit a species distribution model (SDM), we must select a modelling method to relate our response data (e.g., presence-background points) and our covariates (e.g., mean annual temperature). This best practice guide is concerned with how to select an appropriate modelling method.</p>
<p>With the abundance of SDM methods to pick from, it can be difficult to know which to choose. Primarily, the modelling method we choose depends on the type of data we want to analyse and the question we want to ask. Methods for species distribution modelling fall into three broad categories: ‘profile’, ‘regression’, or ‘machine learning’. In addition to these main types, there are ensemble models that combine analyses from multiple different modelling methods into a single result. We will confine our discussion in this guide to regression and machine learning-based methods. There’s no fundamental distinction between these two categroies, however the literature refers to the models under these headings and so we keep to convention here.</p>
<p>In this guide we go into detail about some common modelling methods currently available as modules in <code>zoon</code>. For each method we will cover which data types they are compatible with, explain the underlying statistical approach, and demonstrate how to fit them in <code>zoon</code>. To keep comparisons straightforward, we fit them all to the same Carolina wren dataset.</p>
<hr>
</div>
<div id="regression-based-methods" class="section level2">
<h2 class="hasAnchor">
<a href="#regression-based-methods" class="anchor"></a>Regression-based methods</h2>
<p>Regression analyses estimate the statistical relationship between a dependent variable (e.g. presence of a species) and one or more independent variables (e.g. environmental covariates). The two regression-based SDMs currently available as <code>zoon</code> modules, logistic regression and generalised additive models, are covered in detail here.</p>
<p>Standard linear models (e.g. <span class="math inline">\(y = c + mx\)</span> <span class="math inline">\((1)\)</span>) assume a linear effect of covariates (<em>x</em> in equation XX). on response variable (<em>y</em> in equation XX). These models assume that the response variable varies linearly with the covariates, and relies on normally-distributed response variables. In contrast, generalised linear models (GLMs) allow the linear models to be related to the response variable via so-called ‘link functions’. These link functions let us use non-normally distributed response variables by transforming them so they can be used within the standard linear model framework.</p>
<div id="logistic-regression" class="section level3">
<h3 class="hasAnchor">
<a href="#logistic-regression" class="anchor"></a>Logistic regression</h3>
<p>Logistic regression is a type of generalised linear model (GLM). It uses the ‘logit’ link function to estimate the probability of a binary response variable (e.g. species presence/absence encoded as 1/0) based on its relationship with our predictor covariates. In the same way that we estimate the slope of a linear relationship (e.g. <em>m</em> in equation XX), logistic regression estimates one regression coefficient (<span class="math inline">\(/beta\)</span> in equation XXX below) for each covariate using maximum likelihood estimation. As in a standard linear model, we also estimate an intercept term (e.g. <em>c</em> in equation XX).</p>
<p><span class="math display">\[logit(Pr(Occurrence)) = Intercept + \beta_1Covariate_1 + \beta_2Covariate_2 + \beta_3Covariate_3\\\]</span> <span class="math inline">\((2)\)</span></p>
<p>The left-hand side of the equation is the link function transformation of the response variable. The right-hand side of this equation is known as the linear predictor.</p>
<p>In <code>zoon</code>, we can fit a <code>LogisticRegression</code> model by choosing it as the model module in our <code>zoon</code> <code>workflow</code>. <code>LogisticRegression</code> uses the <code>glm</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Logistic &lt;-<span class="st"> </span><span class="kw">workflow</span>(<span class="dt">occurrence =</span> <span class="kw">SpOcc</span>(<span class="st">"Thryothorus ludovicianus"</span>,
                                        <span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                     <span class="dt">covariate =</span> <span class="kw">Bioclim</span>(<span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                     <span class="dt">process =</span> <span class="kw">Chain</span>(StandardiseCov,
                                     <span class="kw">Background</span>(<span class="dv">1000</span>)),
                     <span class="dt">model =</span> LogisticRegression,
                     <span class="dt">output =</span> <span class="kw">PrintMap</span>(<span class="dt">points =</span> <span class="ot">FALSE</span>))</code></pre></div>
<p><img src="Choosing_A_Modelling_Method_files/figure-html/Logistic_Regression-1.png" width="672" style="display: block; margin: auto;"></p>
</div>
<div id="generalised-additive-model" class="section level3">
<h3 class="hasAnchor">
<a href="#generalised-additive-model" class="anchor"></a>Generalised additive model</h3>
<p>Generalised additive models (GAMs) are similar to GLMs but allow a bit more flexibility. GAMs with a logit link function can fit binary data such as presence-background or presence-absence datasets (different link functions allow the use of different types of data). The main difference between GAMs and GLMs is that GAMs do not estimate regression coefficients. Instead, the ‘linear predictor’ is the sum of a set of ‘smoothing functions’ (see equation XX below). Smoothing functions allow the inclusion of non-linear effects of covariates in our model. By using smoothing functions instead of regression coefficients, we can fit complex, non-linear relationships between our dependent and independent covariates. As GAMs are non-parametric models, the shape of the predictor function for a covariate is entirely dependent on the data and not set by a small number of model parameters (such as defining a quadratic term in a GLM).</p>
<p><span class="math display">\[logit(Pr(Occurrence)) = Intercept + f_1(Covariate_1) + f_2(Covariate_2) + f_3(Covariate_3)\\\]</span></p>
<p>If we use smoothing functions without any restrictions, however, it is possible to ‘overfit’ our model to our data, creating a linear predictor that is too complex. To avoid this, GAMs use ‘penalised likelihood maximisation,’ which penalises the model for each additional smoothing function (or ‘wiggliness’). Overfit models are too tailored to the specific dataset they were fit too (picking up on the little quirks and random noise), which means they tend to make poor predictions.</p>
<p>In <code>zoon</code>, the <code>mgcv</code> model module fits a GAM using the <code>mgcv</code> package. To fit a GAM we need to define a couple of parameters that determine how wiggly and complex the linear predictor can be. Specifically, we need to define the parameter <em>k</em>, which sets the maximum limit on the degrees of freedom, and a penalised smoothing basis, <em>bs</em>, that specifies the penalty for additional smoothing functions. We are, in effect, balancing the ability to represent the underlying ‘truth’ reasonably well with the risk of overfitting the model to the dataset. You can find more details on selecting these parameters using <code><a href="http://www.rdocumentation.org/packages/mgcv/topics/choose.k">?mgcv::choose.k</a></code> and <code><a href="http://www.rdocumentation.org/packages/mgcv/topics/smooth.terms">?mgcv::smooth.terms</a></code>.</p>
<p>Let’s just start by fitting a GAM using the default settings in our <code>workflow</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">GAM &lt;-<span class="st"> </span><span class="kw">workflow</span>(<span class="dt">occurrence =</span> <span class="kw">SpOcc</span>(<span class="st">"Thryothorus ludovicianus"</span>,
                                   <span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                <span class="dt">covariate =</span> <span class="kw">Bioclim</span>(<span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                <span class="dt">process =</span> <span class="kw">Chain</span>(StandardiseCov,
                                <span class="kw">Background</span>(<span class="dv">1000</span>)),
                <span class="dt">model =</span> <span class="kw">mgcv</span>(<span class="dt">k =</span> -<span class="dv">1</span>,
                             <span class="dt">bs =</span> <span class="st">"tp"</span>),
                <span class="dt">output =</span> <span class="kw">PrintMap</span>(<span class="dt">points =</span> <span class="ot">FALSE</span>))</code></pre></div>
<p><img src="Choosing_A_Modelling_Method_files/figure-html/GAM-1.png" width="672" style="display: block; margin: auto;"></p>
</div>
</div>
<div id="machine-learning-methods" class="section level2">
<h2 class="hasAnchor">
<a href="#machine-learning-methods" class="anchor"></a>Machine learning methods</h2>
<p>Machine learning is a field of computer science where modelling methods learn from and make predictions on data.</p>
<div id="maxentmaxnet" class="section level3">
<h3 class="hasAnchor">
<a href="#maxentmaxnet" class="anchor"></a>MaxEnt/MaxNet</h3>
<p>MaxEnt is one of the most widely used SDM modelling methods <span class="citation">(Elith <em>et al.</em> 2011)</span>. MaxEnt is used only for presence-background data. Unlike the regression-based analyses discussed above, MaxEnt does not use maxmimum likelihood estimation. Instead, as its name suggests, it uses maximum entropy estimation.</p>
<p>Maximum entropy estimation compares the probability density of environmental covariates across the landscape where the species is present (<span class="math inline">\(f_1(z)\)</span>) with the probability density of the covariates at a random selection of background points (<span class="math inline">\(f(z)\)</span>). The estimated ratio of <span class="math inline">\(f_1(z)/f(z)\)</span> provides insight on which covariates are important, and establishes the relative suitability of one site over another.</p>
<p>MaxEnt must estimate <span class="math inline">\(f_1(z)\)</span> such that it is consistent with our occurrence data, but as there are many possible distributions that can accomplish this it chooses the one closest to <span class="math inline">\(f(z)\)</span>. Minimising the difference between the two probability densities is sensible as, without species absence data, we have no information to guide our expectation of species’ preferences for one particular environment over another.</p>
<p><strong>I’m finding the next two paragraphs hard to simplify any further. I do think the next paragraph is important to understanding MaxEnt under the hood, but maybe it doesn’t need to be understood for the average user? Maybe stick it under some Advanced User/Side Note/More detail heading?</strong></p>
<p>The distance from <span class="math inline">\(f(z)\)</span> represents the relative entropy of <span class="math inline">\(f_1(z)\)</span> with respect to <span class="math inline">\(f(z)\)</span>. Minimising the relative entropy is equivalent to maximising the entropy (hence, MaxEnt) of the ratio <span class="math inline">\(f_1(z)/f(z)\)</span>. This model can be described as maximising entropy in geographic space, or minimising entropy in environmental space.</p>
<p>During the model fitting procedure, MaxEnt needs to estimate coefficient values such that they meet the above constraints, yet to not fit them too closely and result in an overfitted model with limited generalisability (and thus would be a poor model for prediction). This is achieved using regularisation, which can be thought of as shrinking the coefficients towards zero by penalising them to balance model fit and complexity. Thus, MaxEnt can be seen as fitting a penalised maximum likelihood model. This method works with presence-background data.</p>
<p>The <code>MaxEnt</code> module uses the <code>maxent()</code> function in the <code>dismo</code> package, and requires a MaxEnt executable file saved in the correct location. The <code>zoon</code> helper function <code>GetMaxEnt()</code> is available to help with this installation. Due to common difficulties in downloading MaxEnt, in this example we will use <code>MaxNet</code> as a subsitute. The <code>MaxNet</code> module uses the <em>maxnet</em> R package to fit MaxEnt models without requiring the user to install the MaxEnt java executable file. You select this model in your <code>workflow</code> as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MaxNet &lt;-<span class="st"> </span><span class="kw">workflow</span>(<span class="dt">occurrence =</span> <span class="kw">SpOcc</span>(<span class="st">"Thryothorus ludovicianus"</span>,
                                      <span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                   <span class="dt">covariate =</span> <span class="kw">Bioclim</span>(<span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                   <span class="dt">process =</span> <span class="kw">Chain</span>(StandardiseCov,
                                   <span class="kw">Background</span>(<span class="dv">1000</span>)),
                   <span class="dt">model =</span> MaxNet,
                   <span class="dt">output =</span> <span class="kw">PrintMap</span>(<span class="dt">points =</span> <span class="ot">FALSE</span>))</code></pre></div>
<p><img src="Choosing_A_Modelling_Method_files/figure-html/MaxNet-1.png" width="672" style="display: block; margin: auto;"></p>
</div>
<div id="boosted-regression-trees" class="section level3">
<h3 class="hasAnchor">
<a href="#boosted-regression-trees" class="anchor"></a>Boosted regression trees</h3>
<p>Boosted regression trees (BRTs) are a machine learning technique that produces a prediction model in the form of an ensemble of weak prediction models (e.g. decision trees). BRTs are known by various names (including gradient boosting machine, or GBM), but BRTs is the name most commonly used in the SDM context.</p>
<p>BRTs differ from the standard regression approach of fitting a single best model (using some information criterion like AIC) by using the ‘boosting’ technique to combine relatively large numbers of simple trees adaptively, optimising predictive performance.</p>
<p>Decision trees partition the predictor space with binary splits to identify the regions with the most homogenous responses to the predictor variables (see Figure X below), and a constant value is then fit to each region (ether the most probable class for classification models, or the mean response for regression models). The growth of a decision tree involves recursive binary splits, such that binary splits are applied to its own outputs until some criterion is met (such as a maximum tree depth). For example, predictor space could be split at a node for mean annual temperature &lt; or &gt;= 10C, and then the &lt; 10C branch split at mean annual rainfall &lt; or &gt;= 500 mm. The “end” of a branch in a tree thus shows the estimated response variable for a given set of covariates e.g. mean annual temperature &gt;= 10C <em>and</em> mean annual rainfall &lt;500 mm.</p>
<div class="figure" style="text-align: centre">
<img src="../vignettes/Images/Decision_Tree_Elith.jpg" alt="*Figure 1. A single decision tree (upper panel), with a response Y, two predictor variables, X1 and X2 and split points t1 , t2 , etc. The bottom panel shows its prediction surface (after Hastie et al. 2001). Image sourced from @elith08" width="190"><p class="caption">
*Figure 1. A single decision tree (upper panel), with a response Y, two predictor variables, X1 and X2 and split points t1 , t2 , etc. The bottom panel shows its prediction surface (after Hastie et al. 2001). Image sourced from <span class="citation">Elith <em>et al.</em> (2008)</span>
</p>
</div>
<p>The ‘boosting’ technique is an iterative procedure that attempts to reduce the deviance of the model by fitting another tree to account for the residuals of the previous tree. That is, each subsequent tree targets the largest amount of unexplained variance from the previous tree to gradually increase emphasis on observations modelled poorly by existing trees. The core of this idea is that it is easier to build and average multiple rules of thumb than to find a single, highly accurate prediction rule.</p>
<p>The <code>GBM</code> module fits a generalised boosted regression model using the <code>gbm</code> package, and it can be fit to both presence-background and presence-absence datasets. There are several tuning parameters that you need to set.</p>
<ul>
<li><p>Maximum number of trees: This is equivalent to setting the number of iterations in the model. As a rule of thumb, more trees is better, but this parameter just sets an upper limit and the optimal number will be selected by cross-validation</p></li>
<li><p>Maximum depth of each tree: This sets the number of nodes (or splits) in the decision trees. Interactions between variables are automatically modelled in BRTs due to the hierarchical structure of trees such that the response to an input variable is dependant on those higher up the tree.</p></li>
<li><p>The learning rate/shrinkage factor: This is the contribution of each tree to the final model average. The sum of fitted values in all trees is multiplied by the learning rate to produce the fitted values in the final model.</p></li>
</ul>
<p>This model can be fit using the following call in your <code>workflow</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">BRT &lt;-<span class="st"> </span><span class="kw">workflow</span>(<span class="dt">occurrence =</span> <span class="kw">SpOcc</span>(<span class="st">"Thryothorus ludovicianus"</span>,
                                   <span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                <span class="dt">covariate =</span> <span class="kw">Bioclim</span>(<span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                <span class="dt">process =</span> <span class="kw">Chain</span>(StandardiseCov, <span class="kw">Background</span>(<span class="dv">1000</span>)),
                <span class="dt">model =</span> <span class="kw">GBM</span>(<span class="dt">max.trees =</span> <span class="dv">1000</span>,
                            <span class="dt">interaction.depth =</span> <span class="dv">5</span>,
                            <span class="dt">shrinkage =</span> <span class="fl">0.001</span>),
                <span class="dt">output =</span> <span class="kw">PrintMap</span>(<span class="dt">points =</span> <span class="ot">FALSE</span>))</code></pre></div>
<p><img src="Choosing_A_Modelling_Method_files/figure-html/BRT-1.png" width="672" style="display: block; margin: auto;"></p>
<p>The <code>XGBoost</code> software is increasingly used in machine learning applications for fitting BRTs to very large datasets. You can use the <code>MachineLearn</code> module to fit BRT models with XGBoost by replacing the model module above with: <code>MachineLearn(method = 'xgbTree')</code>.</p>
</div>
<div id="randomforest" class="section level3">
<h3 class="hasAnchor">
<a href="#randomforest" class="anchor"></a>RandomForest</h3>
<p>Similar to the BRTs in the <code>GBM</code> module, random forests are a machine learning technique that make use of an ensemble of weak prediction models (i.e. decision trees). Where BRTs build each subsequent tree in order to explain the most poorly modelled observations of previous trees, each tree in a random forest model is fit independently of each other to a boot-strapped sample of the data. The final predicted output is the mean prediction of all of the trees, which corrects for the tendency of decision trees to over-fit their data.</p>
<p>The <code>RandomForest</code> module can be fit to presence-background or presence-absence data using the following call in your <code>workflow</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">RandomForest &lt;-<span class="st"> </span><span class="kw">workflow</span>(<span class="dt">occurrence =</span> <span class="kw">SpOcc</span>(<span class="st">"Thryothorus ludovicianus"</span>,
                                            <span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                         <span class="dt">covariate =</span> <span class="kw">Bioclim</span>(<span class="dt">extent =</span> <span class="kw">c</span>(-<span class="fl">138.71</span>, -<span class="fl">52.58</span>, <span class="fl">18.15</span>, <span class="fl">54.95</span>)),
                         <span class="dt">process =</span> <span class="kw">Chain</span>(StandardiseCov, <span class="kw">Background</span>(<span class="dv">1000</span>)),
                         <span class="dt">model =</span> RandomForest,
                         <span class="dt">output =</span> <span class="kw">PrintMap</span>(<span class="dt">points =</span> <span class="ot">FALSE</span>))</code></pre></div>
<p><img src="Choosing_A_Modelling_Method_files/figure-html/RandomForest-1.png" width="672" style="display: block; margin: auto;"></p>
<hr>
</div>
</div>
<div id="choosing-a-modelling-method" class="section level2">
<h2 class="hasAnchor">
<a href="#choosing-a-modelling-method" class="anchor"></a>Choosing a modelling method</h2>
<p>The most common SDM modelling methods have been highlighted above, but the question remains about whih method to choose. In short, there are no set rules to determine which method you should use. The way that the methods operate can rule some options out. For example, if you have presence-absence data you wouldn’t use MaxEnt (which only accepts presence-only data), or if you cared about inference more than prediction you would possibly pick a GLM- or GAM-based method over a decision tree-based one. Even after making some of these decisions you would still have multiple methods to pick from, and while there <em>may</em> a ‘best’ method there is no expert consensus. One option is to try multiple options and determine which one best fits your data, or combine multiple methods as part of an ensemble model. Choice of modelling method or methods is an important aspect of species distribution modelling, and is at least partly dependent on the type of analysis you are trying to perform. This guide has outlined the options available, but ultimately the choice of modelling method is up to you.</p>
<hr>
<div id="refs" class="references">
<div id="ref-elith08">
<p>Elith, J., Leathwick, J.R. &amp; Hastie, T. (2008). A working guide to boosted regression trees. <em>Journal of Animal Ecology</em>, <strong>77</strong>, 802–813.</p>
</div>
<div id="ref-elith11">
<p>Elith, J., Phillips, S.J., Hastie, T., Dudík, M., Chee, Y.E. &amp; Yates, C.J. (2011). A statistical explanation of maxent for ecologists. <em>Diversity and Distributions</em>, <strong>17</strong>, 43–57.</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#regression-based-methods">Regression-based methods</a></li>
      <li><a href="#machine-learning-methods">Machine learning methods</a></li>
      <li><a href="#choosing-a-modelling-method">Choosing a modelling method</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Nick Golding, David Wilkinson, Liz Martin, Saras Windecker.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
