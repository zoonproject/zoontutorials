---
title: "Introduction to SDMs"
author: "zoontutorials team"
date: "6 February 2017"
output:
  rmarkdown::html_vignette:
    toc: yes
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Introduction to SDMs}
  %\VignetteEncoding{UTF-8}
---

```{r eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# set up knitr options
knitr::opts_chunk$set(message = FALSE,
               warning = FALSE,
               fig.align = 'center',
               dev = c('png'),
               cache = TRUE)

```

# Introduction
## Why do we fit species distribution models?
In ecology, we often want to understand where a species is located in the environment and why they occur there. Sometimes we ask these questions to gain more understanding of a species and other times we need to know where a species is so we can manage it.

We typcially consider that species exist within their "ecological niche." In contrast to geographic space, the ecological niche does not describe a physical place, but rather the environmental conditions required for a species. 

Ecologists typically consider species' ecological niche space to be constrained by three dominant factors: the abiotic environment, the biotic environment, and the species' movement. Characteristics of the ecological niche include the abiotic and biotic habitat, the resources it obtains from the habitat, and the species' activity pattern that allow it to utilise its space. Examples of these include the climate required for a species to survive, the local vegetation types it depends on, and its abillity to traverse different landscapes, respectively. The intersection of the abiotic and biotic environmental conditions constitutes the "fundamental niche," or where the species could physiologically occur given what we know of its biology and ecology. Experience tells us, however, that species are not always located where we expect them to be. Their "realised niche" is where they actually exist within the bounds of the environmental space where they could potentially exist. 

## What is a species distribution model?
Species distribution models estimate the probabilty of occurrence of species along environmental gradients. They do this by estimating the correlation between environmental variables and species occurrence data. For example, using SDMs, we can estiamte the probability a species of bird will use forest habitat with high tree cover compared to open habitat with low tree cover. We can take these statisical relationships and project them onto geographic space, which allows us to visualise on a map how the probability of species occurrence varies in geographic space.

We have visualised this theory in Figure 1 below. This dataset uses presence data of the Carolina Wren as well as a suite of environmental predictors such as cover of different forest types. In the top left corner we have mapped onto geographic space the records of species occurrence (black dots) as well as the background points we will use in our model. In the top right we see these same points plotted in environmental space against two covariates. We can see that the presence points are clustered at higher percents of deciduous forest and lower percents of mixed forest. The model uses this presence background data to construct predictions of species occurrence in environmental space, as seen in the bottom right plot. In the final plot, bottom left, we see these probability predictions mapped back onto geographic space in a way that allows us to understand where and by what drivers the species is likely to occur. 

```{r echo = F, out.width= 700}
knitr::include_graphics("../vignettes/Intro_Module_files/SDM_theory.png")
```
Figure 1: Species Distribution Model Theory. Presence-background points plotted on geographic space, on environmental space, and probability of occurrence predictions plotted on environmental and geographic space. 

There are many types of species distribution models and the field is rapidly expanding. `zoon` is concerned with correlative SDMs, as described above, which are the most widely used SDM. This tutoiral will focus on distribution models which estimate probability of occurrence, however, we could also use species abundance data to estimate how abundance varies along environemntal gradients. As well as correlative SDMs, there are also mechanistic SDMs. Where correlative SDMs use statistics to estimate relationships between occurrence data and environmental covariates, mechanistic SDMs use mathematical relationships between species energy requirements and environmental covaraites. Where correlative SDMs estimate a species realised niche, mechanistic SDMs estimates the fundemental niche. The field of mechanistic models is ... and we encourage the read to pursue their interest further, as we leave the topic here. 

# How do I fit a species distribution model?
We implement a species distribution model with five steps:
    1. Occurence: We first gather and format our species occurrence data.
    2. Covariates: Next, we gather and format the environmental variables we believe are important to our species of interest.
    3. Process: Often our data, both occurrence and environmental, will need some pre-processing before we fit our models.
    4. Model: We then fit one or more statistical models to our data to estimate species probability of occurrence.
    5. Output: Finally, after fitting our model, we produce model outputs, such as graphs and maps, to enable us to make ecological inference about the species.
    
The `zoon` workflow is structured around these five steps and designed to make building and fitting SDMs straight-foward and reproducible. The primary zoon function is `workflow()`, which we use to fit the SDM. The workflow function has five arguments, one for each step in the SDM fitting process. For each argument, we need only to select a 'module.' The modules we choose in each step determine what type of model we run with what data and what outputs we produce. This tutorial will guide you through the process of selecting a module for each argument of the `workflow()` function. Along the way, we'll introduce some key factors that you should consider when fitting and evaluating an SDM.

But first, let's fit a quick and simple SDM with `zoon` as a means of introduction. Don't forget to load the package!

```{r message=FALSE, warning=FALSE, cache=TRUE}
library(zoon)
```

A basic workflow could look like this:  
```{r message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7}
zoon_workflow <- workflow(occurrence = Lorem_ipsum_UK,
                             covariate = UKBioclim,
                             process = OneHundredBackground,
                             model = RandomForest,
                             output = PrintMap)
```

In this workflow, we have loaded the *Lorem ipsum* presence-only occurrence data for the UK, loaded the Bioclim environmental covariates for the UK, selected 100 background occurrence data (more on this later), fit a Random Forest model, and printed a map. The map shows us how the probability of occurrence of *Lorem ipsum* varies across the UK. Throughout this tutorial we will guide you step-by-step through each of the arguments in a workflow as we update this `zoon_workflow`.

`zoon` comes with several pre-existing modules for each argument, and we will go through a selection of these modules in more detail in this tutorial. You might like to explore some different combinations yourself, and you can find more information by running the `GetModuleList()` command.

# Zoon SDM Workflow
## Step 1. Occurrence
Species distribution models are fitted with species occurrence data, which is available in three formats: presence-only, presence-background, and presence-absence. Less commonly, species distribution models can be fitted with abundance data. 

* Presence-only data is usually sourced from museum or herbarium records, and is a list of all recorded sightings/captures of a species with its location. 

* Presence-background data is a type of presence-only data that combines presence records with randomly generated background points, also called 'pseudo-absences.' This is the more common of the two types. 

* Presence-absence data generally comes from structured field surveys where the presence *or* absence of the target species is recorded for a given site.

Presence-only data is widely and freely accesible only and as a result is more commonly used than presence-absence data. As such, we write this tutorial for presence-only data and note any necessary alterations for presence-absence data.

The first module required in a `workflow()` is `occurrence` and it is where we load our species occurrence data. There are three methods for loading data into your workflow depending where the data is sourced: we can use pre-existing `occurrence` modules in `zoon` like `Lorem_ipsum_UK`, download data from an online repository using `SpOcc`, or load in our own data from a local computer using `LocalOccurrenceData`. 

`zoon` has several functions available to view the contents of each module in the workflow. For example, we can view our species occurrence data using the `Occurrence()` function (using the `head()` function to see only the first six lines):

```{r eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
head(Occurrence(zoon_workflow))
```

The first two columns provide the geographic location of the observation (as longitude and latitude), the third column is the observation value (1 = presence, 0 = absence), the fourth column is the type of observation, and the last column identifies the "fold" the data point is located in if utilising cross-validation (covered later in the section of `Process` modules, but a default model can be considered to always have one fold). 

## Step 2. Covariates

The second module required in a `workflow` is for environmental data. As with the `occurrence` module, there are three ways to load `covariate` data into the model: pre-existing `zoon` modules like `CarolinaWrenRasters`, data from online sources such as `Bioclim`, and our own data from a local computer using `LocalRaster`.

Using the `Covariate()` accessor function shows important details of our raster stack, including the extent of the dataset, the coordinate projection scheme (here, WGS84), and minimum/maximum value for the variables. 

```{r eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
Covariate(zoon_workflow)
```

We can use the `?'RasterStack-class'` command to find a more detailed summary of the data format. 

Now using what we've learned here, lets update `zoon_workflow` so that we can build an SDM for the Carolina Wren in the USA. `zoon` has pre-loaded dataset modules for the Carolina Wren which is a common species in North America whose range reaches from southern Canada to north-eastern Mexico, but the dataset has been cropped to the extent of the contiguous USA. As presence-only data is the most commonly used data type for SDMs lets use the presence-only version of the dataset using `CarolinaWrenPO`, and we get the environmental data from `CarolinaWrenRasters`.

```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
zoon_workflow <- ChangeWorkflow(workflow = zoon_workflow,
                                occurrence = CarolinaWrenPO,
                                covariate = CarolinaWrenRasters)
```

## Step 3. Process

Now that we have loaded in our species and environmental data using the `occurrence` and `covariate` modules, the `process` modules will perform any pre-processing of our data required before fitting the model itself. This is where we can modify our raw data by removing poor data points using the `Clean` module or standardising our covariates using `StandardiseCov`, generate the background data points required for presence-only data analysis using `Background`, add interaction terms between our covariates using `addInteractions`, or set up model validation methods using modules like `CrossValidate`.

Lets see how the mimimum/maximum values for our environmental layers change after we standardise our covariates. As we still need to generate background data to work with our presence-only dataset (more on this below), we can use the `Chain()` function to run multiple models in a single workflow argument.

```{r eval=TRUE, cache=TRUE}
Covariate(zoon_workflow)   # Before standardisation
```

```{r eval=TRUE, warning=FALSE, message=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
zoon_workflow <- ChangeWorkflow(workflow = zoon_workflow,
                                process = Chain(Background(n=100), StandardiseCov))

```

```{r eval=TRUE, cache=TRUE}
Covariate(zoon_workflow)
```

We can see that the standardised variables have a smaller range and are centered around zero.

In some instances you may not require a `process` module in your `workflow`, however, it is a mandatory argument and so the `NoProcess` module can be used as a 'blank' module.

Since we are using presence-only data in our model we need to generate some background data, also known as pseudo-absences. Depending on the type of SDM model (see next section), this data is used to either sample the range of environmental space in the landscape to compare it to where the species in question has been found, or as a non-presence class of data. We also want to standardise our covariates, so to use multiple modules in an argument we can use the `Chain()` function. Here we use `StandardiseCov` to standardise our covariates and  `Background` to generate 100 background points.

```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
zoon_workflow <- ChangeWorkflow(workflow = zoon_workflow,
                                process = Chain(StandardiseCov, Background(n = 100)))
```

## Step 4. Model

Arguably the most important part of the `workflow` is the `model` module. **actually, probably not due to the variation in results with model choice** *but would that not mean that it is the most important since it can have such a large effect?* **How can it be the most important if we have no way of knowing which model is correct? I.e., they're all wrong, you just need to decide how you want to be wrong. The things that influence varition in model results *within* a model, I argue, are more important** This is where we choose which type of SDM you want to fit to our data. There are multiple different SDM methods to choose from **(add Elith paper reference)** and each have their mertis. A few more common examples include the `LogisticRegression`, `mgcv`, `MaxEnt`, `RandomForest`, and `GBM` modules. For more detail on these methods you can refer to the "Choosing A Model" vignette **link later**.

Now, let's update our `workflow` with another common model type, logistic regression. We do this by using the aptly names `LogisticRegression` module.

```{r eval=TRUE, warning=FALSE, message=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
zoon_workflow <- ChangeWorkflow(workflow = zoon_workflow,
                                model = LogisticRegression)

```


## Step 5. Output
It is finally time to check out our results. We'll continue with our zoon_workflow object, which we've just updated to use a logistic regression statistical model.

We often want to see how our predictions of probability of occurrence in environemntal space fit onto real geographic space. We do this by projecting our predictions onto a map using the module 'PrintMap'.


```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}

zoon_workflow <- ChangeWorkflow(workflow = zoon_workflow,
                                output = InteractiveMap)

```

```{r hidden chunk to embed interative map in html}


```
The `InteractiveMap` module produces a map of the probability of occurrence on the geographic region of our study, in our example the USA, that we can interact with. The map includes a scale from light green to blue, so we can interpret the map and also plots our raw data on top of the map so we can see how our data align with model predictions. We can click on our raw data to get information about it.

The map produced by the `InteractiveMap` module shows our model of Carolina wren occurrence has predicted that the species is most likely to occur in the southeat of the country and is less likely to exist in the northwest of the country. These quantitative predictions fit with a qualitative analysis of our data. We can see most of our presence records (red dots) are in the southeast and the absence records are in the northwest.

Now we've seen how our model of Carolina Wren occurrence varies over geographic space, we can look more closely at what is driving that variation in occurrence probability. That is, how does the probability of occurrence for the species vary along the environmental gradients we included in our model. Remember, we included climatic variables 

```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
zoon_workflow <- ChangeWorkflow(zoon_workflow,
                                output = ResponseCurveViz(1:4))
```

Now we've plotted our predictions in both geographic and environmental space, we should test how good our model fit is. That is, how well does our model fit the data we built it with. There's lots of different way sto do this, which we expand on in our 'Model Validation' guide (*linky link*).

One simple and common statistic is the Area under the receiver operating curve or AUC. The AUC measures how well our model predicts our observed presences and absences. It ranges from 0 to 1, where 0.5 means our model is no better than random and one means our model is a perfect predictor of our data.

```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
zoon_workflow <- ChangeWorkflow(zoon_workflow,
                                output = ROCcurve)
```


## Putting it all together
Now that we have seen how to use each argument in the `workflow()` function it is time to put all of the pieces together and fit our own SDM within `zoon`. Since MaxEnt it is the most popular SDM methodology, we will fit a MaxEnt model to our Carolina Wren presence-background data set, generate 1000 background samples, and display our results in a map without our datapoints displayed. We have covered each of the necesssary modules previously, and here we will run them together to form a complete `workflow()`.

```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
Logistic_Regression_Workflow <- workflow(occurrence = CarolinaWrenPO,
                                         covariate = CarolinaWrenRasters,
                                         process = Background(1000),
                                         model = LogisticRegression,
                                         output = PrintMap(points = FALSE))
```


MaxEnt is arguably one of the modt widley used SDM methodologies, so let's fit a MaxEnt model. Now run the exact same `workflow()` but switch to a `MaxEnt` model. You can use the output modules to see how they compare.


```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7, cache=TRUE}
MaxEnt_Workflow <- workflow(occurrence = CarolinaWrenPO,
                            covariate = CarolinaWrenRasters,
                            process = Background(1000),
                            model = MaxEnt,
                            output = PrintMap(points = FALSE))

```



There are some obvious differences in the predicted distribution maps of these two approaches. The only thing to change betweeen the two workflows is our model of choice, so what causes the difference? Check out our more detailed guide on SDM model algorithm selection here **(insert plug for future guides)**


# Conclusion
*Liz happy to write to pair with the intro*

